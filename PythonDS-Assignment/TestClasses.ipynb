{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'/home/aman/Desktop/software-engg-lab-2022S/PythonDS-Assignment/data/imgs/3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "image = np.array(im1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class FlipImage(object):\n",
    "    '''\n",
    "        Flips the image.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, flip_type='horizontal'):\n",
    "        '''\n",
    "            Arguments:\n",
    "            flip_type: 'horizontal' or 'vertical' Default: 'horizontal'\n",
    "        '''\n",
    "        if flip_type not in ['horizontal', 'vertical']:\n",
    "            raise ValueError('flip_type must be either horizontal or vertical')\n",
    "        self.flip_type = flip_type\n",
    "\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL image)\n",
    "        '''\n",
    "        if self.flip_type == 'horizontal':\n",
    "            return np.fliplr(image)\n",
    "        else:\n",
    "            return np.flipud(image)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_image = FlipImage('horizontal')(image)\n",
    "Image.fromarray(flipped_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RotateImage(object):\n",
    "    '''\n",
    "        Rotates the image about the centre of the image.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, degrees):\n",
    "        '''\n",
    "            Arguments:\n",
    "            degrees: rotation degree.\n",
    "        '''\n",
    "        self.degrees = degrees\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL image)\n",
    "        '''\n",
    "        image1 = Image.fromarray(sample)\n",
    "        image1 = image1.rotate(self.degrees)\n",
    "        return np.array(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\n"
     ]
    }
   ],
   "source": [
    "rotated_image = RotateImage(69)(image)\n",
    "Image.fromarray(rotated_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RescaleImage(object):\n",
    "    '''\n",
    "        Rescales the image to a given size.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        '''\n",
    "            Arguments:\n",
    "            output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "        '''\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL image)\n",
    "\n",
    "            Note: You do not need to resize the bounding boxes. ONLY RESIZE THE IMAGE.\n",
    "        '''\n",
    "        if(type(self.output_size)==int):\n",
    "            h, w = image.shape[:2]\n",
    "            if(h>w):\n",
    "                new_w = self.output_size\n",
    "                new_h = int(h*self.output_size/w)\n",
    "            else:\n",
    "                new_h = self.output_size\n",
    "                new_w = int(w*self.output_size/h)\n",
    "            image1 = Image.fromarray(image)\n",
    "            image1 = image1.resize((new_w, new_h))\n",
    "            return np.array(image1)\n",
    "        else:\n",
    "            image1 = Image.fromarray(image)\n",
    "            image1 = image1.resize(self.output_size)\n",
    "            return np.array(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = RescaleImage((100, 500))(image)\n",
    "Image.fromarray(resized_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "\n",
    "class GaussBlurImage(object):\n",
    "    '''\n",
    "        Applies Gaussian Blur on the image.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, radius):\n",
    "        '''\n",
    "            Arguments:\n",
    "            radius (int): radius to blur\n",
    "        '''\n",
    "        self.radius = radius\n",
    "        \n",
    "\n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL Image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL Image)\n",
    "        '''\n",
    "        image1 = Image.fromarray(image)\n",
    "        image1 = image1.filter(ImageFilter.GaussianBlur(self.radius))\n",
    "        return np.array(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = GaussBlurImage(1)(image)\n",
    "Image.fromarray(blurred_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class CropImage(object):\n",
    "    '''\n",
    "        Performs either random cropping or center cropping.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, shape, crop_type='center'):\n",
    "        '''\n",
    "            Arguments:\n",
    "            shape: output shape of the crop (h, w)\n",
    "            crop_type: center crop or random crop. Default: center\n",
    "        '''\n",
    "        self.shape = shape\n",
    "        if crop_type not in ['center', 'random']:\n",
    "            raise ValueError('crop_type must be either center or random')\n",
    "        self.crop_type = crop_type\n",
    "\n",
    "\n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL image)\n",
    "        '''\n",
    "        height, width = self.shape\n",
    "        if (self.shape[0] > image.shape[0]) or (self.shape[1] > image.shape[1]):\n",
    "            raise ValueError('Crop shape must be smaller than image shape')\n",
    "        if self.crop_type == 'center':\n",
    "            y = int((image.shape[0] - height) / 2)\n",
    "            x = int((image.shape[1] - width) / 2)\n",
    "        else:\n",
    "            y = np.random.randint(0, image.shape[0] - height)\n",
    "            x = np.random.randint(0, image.shape[1] - width)\n",
    "        return image[y:y + height, x:x + width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\n"
     ]
    }
   ],
   "source": [
    "cropped_image = CropImage((180, 200), 'random')(image)\n",
    "Image.fromarray(cropped_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    '''\n",
    "        A class for the dataset that will return data items as per the given index\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation_file, transforms = None):\n",
    "        '''\n",
    "            Arguments:\n",
    "            annotation_file: path to the annotation file\n",
    "            transforms: list of transforms (class instances)\n",
    "                        For instance, [<class 'RandomCrop'>, <class 'Rotate'>]\n",
    "        '''\n",
    "        self.annotations_path = annotation_file\n",
    "        with open(annotation_file) as file:\n",
    "            list_of_annotations = [json.loads(line) for line in file]\n",
    "        self.annotations = list_of_annotations\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "            return the number of data points in the dataset\n",
    "        '''\n",
    "        return len(self.annotations)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "            return the dataset element for the index: \"idx\"\n",
    "            Arguments:\n",
    "                idx: index of the data element.\n",
    "\n",
    "            Returns: A dictionary with:\n",
    "                image: image (in the form of a numpy array) (shape: (3, H, W))\n",
    "                gt_png_ann: the segmentation annotation image (in the form of a numpy array) (shape: (1, H, W))\n",
    "                gt_bboxes: N X 5 array where N is the number of bounding boxes, each \n",
    "                            consisting of [class, x1, y1, x2, y2]\n",
    "                            x1 and x2 lie between 0 and width of the image,\n",
    "                            y1 and y2 lie between 0 and height of the image.\n",
    "\n",
    "            You need to do the following, \n",
    "            1. Extract the correct annotation using the idx provided.\n",
    "            2. Read the image, png segmentation and convert it into a numpy array (wont be necessary\n",
    "                with some libraries). The shape of the arrays would be (3, H, W) and (1, H, W), respectively.\n",
    "            3. Scale the values in the arrays to be with [0, 1].\n",
    "            4. Perform the desired transformations on the image.\n",
    "            5. Return the dictionary of the transformed image and annotations as specified.\n",
    "        '''\n",
    "\n",
    "        annotation = self.annotations[idx]\n",
    "\n",
    "        path_to_dir = self.annotations_path.replace('annotations.jsonl', '')\n",
    "        image_path = path_to_dir + annotation['img_fn']\n",
    "        image = np.array(Image.open(image_path))\n",
    "\n",
    "        #Perform the desired transformations on the image.\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                image = transform(image)\n",
    "        \n",
    "        #Scale the values in the arrays to be with [0, 1].\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image / 255.0\n",
    "\n",
    "        gt_png_ann = np.array(Image.open(path_to_dir + annotation['png_ann_fn']))\n",
    "        gt_png_ann = gt_png_ann[..., np.newaxis].transpose((2, 0, 1))\n",
    "        gt_png_ann = gt_png_ann / 255.0\n",
    "\n",
    "        print(image.shape)\n",
    "        print(gt_png_ann.shape)\n",
    "\n",
    "        #Return the dictionary of the transformed image and annotations as specified.\n",
    "        return {'image': image, 'gt_png_ann': gt_png_ann, 'gt_bboxes': annotation['bboxes']}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 200, 200)\n",
      "(1, 375, 500)\n",
      "(3, 200, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(r'/home/aman/Desktop/software-engg-lab-2022S/PythonDS-Assignment/data/annotations.jsonl', [RescaleImage((1000, 500)), GaussBlurImage(5), CropImage((200,200), 'random'), FlipImage(), RotateImage(90)])\n",
    "image = data[0]['image']\n",
    "print(image.shape)\n",
    "image = (image*255).astype(np.uint8)\n",
    "image = image.transpose((1, 2, 0))\n",
    "Image.fromarray(image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cfa2540a53c64e5d30012a4f2d5efa8135932ea365fa8a35cfd1bb327d65cbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('anaconda3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
